{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYMyRHDpRVHp",
    "outputId": "6bb75a20-bd90-48f1-9b77-ca410522352f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 308 µs (started: 2022-10-14 17:44:37 +00:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.52 ms (started: 2022-10-14 17:44:37 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164755\n",
      "time: 7.74 s (started: 2022-10-14 17:44:38 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Query para obtener la data de 3 días antes, considerando que el enlace de la foto, \n",
    "# el nombre del transportista y su rut, no sean nulos\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT DISTINCT transport_ord_id as SOC, i.url as url, shipment.plate_num as plate_num, \n",
    "provider.doc_id as provider_id, \n",
    "provider.doc_verify_digit as provider_verify_digit,\n",
    "provider.name as provider_name, driver.doc_id as driver_id, \n",
    "driver.doc_verify_digit as driver_verify_digit,\n",
    "driver.name as driver_name, driver.last_name as driver_last_name,\n",
    "DATETIME(event_crte_tmst, 'America/Santiago') as event_crte_tmst, dfl_crte_tmst\n",
    "FROM \n",
    "`tc-sc-bi-bigdata-corp-tsod-dev.image_recognition.btd_scha_fal_trmg_api_transport_order_temp`,\n",
    "unnest(image) as i\n",
    " \n",
    "WHERE\n",
    "  i.url is not null\n",
    "  and provider.name is not null\n",
    "  and provider.doc_id is not null\n",
    "  and DATE(event_crte_tmst, 'America/Santiago') = current_date() - 2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_images = client.query(sql).to_dataframe()\n",
    "\n",
    "print(len(df_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180776\n",
      "time: 141 ms (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# eliminar filas con urls duplicados\n",
    "df_images = df_images.drop_duplicates(['url'])\n",
    "# resetear indices\n",
    "df_images = df_images.reset_index()\n",
    "# eliminar columna index\n",
    "df_images = df_images.drop(['index'], axis = 1)\n",
    "print(len(df_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.9 ms (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# numero de kernels\n",
    "nk = 2\n",
    "# escoger valores unicos de SOC\n",
    "soc = df_images.SOC.unique()\n",
    "# dividirlos en nk partes (para los nk kernels)\n",
    "import numpy as np\n",
    "partitions = np.array_split(soc, nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.83 ms (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# seleccionar de manera random 2000 soc de la primera partición\n",
    "# de modo que al final se obtengan alrededor de 5000 filas\n",
    "# por kernel\n",
    "from numpy import random\n",
    "partitions1 = random.choice(partitions[0], size=5000, replace=False, p=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.8 ms (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# se obtienen las filas que estan en la partición \n",
    "df_images1 = df_images.loc[df_images.SOC.isin(partitions1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.79 ms (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# se resetea el indice y se elimina la columna 'index'\n",
    "df_images1 = df_images1.reset_index().drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12591"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.7 ms (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# imprimir largo dataset\n",
    "len(df_images1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.92 ms (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# prueba\n",
    "#sql = \"\"\"\n",
    "#SELECT transport_ord_id as SOC, i.url as url, shipment.plate_num as plate_num, \n",
    "#provider.doc_id as provider_id, \n",
    "#provider.doc_verify_digit as provider_verify_digit,\n",
    "#provider.name as provider_name, driver.doc_id as driver_id, \n",
    "#driver.doc_verify_digit as driver_verify_digit,\n",
    "#driver.name as driver_name, driver.last_name as driver_last_name,\n",
    "#event_crte_tmst, dfl_crte_tmst\n",
    "#FROM \n",
    "#`tc-sc-bi-bigdata-corp-tsod-dev.image_recognition.btd_scha_fal_trmg_api_transport_order`,\n",
    "#unnest(image) as i\n",
    "#\n",
    "#LIMIT 500\n",
    "#\"\"\"\n",
    "#\n",
    "#df_images = client.query(sql).to_dataframe()\n",
    "#\n",
    "#df_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.06 ms (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "df = df_images1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOC                      False\n",
       "url                      False\n",
       "plate_num                False\n",
       "provider_id              False\n",
       "provider_verify_digit     True\n",
       "provider_name            False\n",
       "driver_id                 True\n",
       "driver_verify_digit       True\n",
       "driver_name               True\n",
       "driver_last_name          True\n",
       "event_crte_tmst          False\n",
       "dfl_crte_tmst            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.69 ms (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKOThTSiRQbs",
    "outputId": "170aad89-9ea4-41b3-a710-ba6e506d30ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 218 µs (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#!pip install ipython-autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUSQ0_cQZ_EG"
   },
   "source": [
    "# Cargar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGcgcEAQgM91",
    "outputId": "463e3ad7-5913-402e-a97e-a4a412f4a3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 685 µs (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_vxYx-kqWM9",
    "outputId": "fd719451-d280-48be-c9e8-0dbe14216e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 344 µs (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "\n",
    "#!pip install albumentations\n",
    "#!pip install pycocotools --quiet\n",
    "\n",
    "# Clone TorchVision repo and copy helper files\n",
    "#!git clone https://github.com/pytorch/vision.git\n",
    "#%cd vision\n",
    "#!git checkout v0.3.0\n",
    "#%cd ..\n",
    "#!cp vision/references/detection/utils.py ./\n",
    "#!cp vision/references/detection/transforms.py ./\n",
    "#!cp vision/references/detection/coco_eval.py ./\n",
    "#!cp vision/references/detection/engine.py ./\n",
    "#!cp vision/references/detection/coco_utils.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JP5zwN_ef-pS",
    "outputId": "a724ab1d-31ea-4a13-c90b-5dc4b797a470"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7ff992d66850>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.98 s (started: 2022-10-14 12:53:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# imporar librerias\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms \n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet101\n",
    "import urllib.request\n",
    "import cv2\n",
    "\n",
    "from ignite.metrics import ClassificationReport\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *\n",
    "\n",
    "from genericpath import exists\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wZHSTyIqRrv",
    "outputId": "62f2acc8-5c73-417e-8e57-497223d12ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 355 ms (started: 2022-10-14 12:53:22 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# basic python and ML Libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We will be reading images using OpenCV\n",
    "import cv2\n",
    "\n",
    "# matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# torchvision libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as torchtrans  \n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# helper libraries\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "\n",
    "# for image augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "a4d602abedbf472ba8443b587b7172a5",
      "e369973d094144a583efe831a749932e",
      "f185edec20214d4f9174944db636ce7b",
      "05887b1a958f4535938c3a9208b4ebaf",
      "a23ac5b3ea2d4bd9950f901288642e51",
      "d482f72576e946f59c20fea52f2973c3",
      "a0c5367310094e45baa5e4f21daa819a",
      "f3c586b991004e839c47ee46163195e8",
      "78b8a851199c421694811a3d2b09d77a",
      "9597f48902e54c7a9989484bcf6a239d",
      "4a4aad02b8d24bffa799e6a5fdd4e006"
     ]
    },
    "id": "HJ34_CvLZ1Ev",
    "outputId": "5405e17e-d28e-4ce8-db14-fa922c63a3c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.87 s (started: 2022-10-14 12:53:22 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnext101_32x8d\n",
    "resnext1 = resnext101_32x8d(pretrained=True)\n",
    "resnext2 = resnext101_32x8d(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R92bFuyRgJyX",
    "outputId": "450b4d59-64ec-47cc-ceb8-aa6f601d110e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 902 µs (started: 2022-10-14 12:53:28 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Cargar backbone resnet y resnext\n",
    "class MultilabelClassifier1(nn.Module):\n",
    "    def __init__(self, n_classes, pretrain_model):\n",
    "        super().__init__()\n",
    "        self.pretrain_model = pretrain_model\n",
    "        self.model_wo_fc = nn.Sequential(*(list(self.pretrain_model.children())[:-1]))\n",
    "\n",
    "        self.classes = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=2048, out_features=n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model_wo_fc(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return {\n",
    "            'label': self.classes(x)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OS4Uf4A_gVOc",
    "outputId": "8845efa9-ce21-4a88-e9d8-6c92c50464df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.9 s (started: 2022-10-14 12:53:28 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# cargar modelo para cara y n° domicilio\n",
    "device = 'cuda'\n",
    "#device = 'cpu'\n",
    "PATH_1 =  '/home/jupyter/Score/Modelos/mlc_model_4.pth'\n",
    "ml_model_1 = MultilabelClassifier1(3, resnext1).to(device)\n",
    "ml_model_dict_1 = torch.load(PATH_1, map_location=torch.device(device))\n",
    "ml_model_1.load_state_dict(ml_model_dict_1['model_state_dict'])\n",
    "#ml_model_1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mu9LDubjFYMP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.648120448645789"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.77 ms (started: 2022-10-14 12:53:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "ml_model_dict_1['validation loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkSUyeTFFa-a",
    "outputId": "5c9f2b62-3e24-4cda-dbca-2fd21f2da7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "time: 446 µs (started: 2022-10-14 12:53:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# obtener epoca óptima\n",
    "optimal_epoch = ml_model_dict_1['epoch']\n",
    "print(optimal_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tm-CvmiBXT3w",
    "outputId": "28e32eb8-7a55-4b9c-d1cd-d929864babc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.25 ms (started: 2022-10-14 12:53:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Cargar backbone -> para modelo 'mlc_model_baseline_data_revisada_1_2.pth'\n",
    "class MultilabelClassifier2(nn.Module):\n",
    "    def __init__(self, n_classes, pretrain_model):\n",
    "        super().__init__()\n",
    "        self.pretrain_model = pretrain_model\n",
    "        self.model_wo_fc = nn.Sequential(*(list(self.pretrain_model.children())[:-1]))\n",
    "\n",
    "        self.classes = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=2048, out_features=3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model_wo_fc(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return {\n",
    "            'label': self.classes(x)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fm-CYGI1XCXP",
    "outputId": "162dbb7e-6eaa-4013-ea2b-70341e55a973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.1 s (started: 2022-10-14 12:53:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# cargar modelo para etiqueta del producto\n",
    "device = 'cuda'\n",
    "#device = 'cpu'\n",
    "PATH_2 = '/home/jupyter/Score/Modelos/mlc_model_baseline_data_revisada_1_2.pth'\n",
    "ml_model_2 = MultilabelClassifier2(3, resnext2).to(device)\n",
    "ml_model_dict_2 = torch.load(PATH_2, map_location=torch.device(device))\n",
    "ml_model_2.load_state_dict(ml_model_dict_2['model_state_dict'])\n",
    "#ml_model_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mh0l415kFkk6",
    "outputId": "8b0071e5-bb2e-4505-cdb6-9e9ee43be2d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0754197467943256"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.47 ms (started: 2022-10-14 12:53:56 +00:00)\n"
     ]
    }
   ],
   "source": [
    "ml_model_dict_2['validation loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMKYd-uWFm9-",
    "outputId": "d8ce9498-5983-4cf8-ad6c-04727ed08573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "time: 438 µs (started: 2022-10-14 12:53:56 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# obtener epoca óptima\n",
    "optimal_epoch = ml_model_dict_2['epoch']\n",
    "print(optimal_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rt2NjM5_p-Ag",
    "outputId": "a776eb5c-2e02-4842-b2bd-da49c11d646c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 564 µs (started: 2022-10-14 12:53:56 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# REFERENCIAR!\n",
    "# función de ayuda para cargar modelo\n",
    "def get_object_detection_model(num_classes):\n",
    "  # load a model pre-trained on COCO\n",
    "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "  # get number of input features for the classifier\n",
    "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "  # replace the pre-trained head with a new one\n",
    "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "32a0c7587cf74eeb98287fdf4767f938",
      "e932cf1b4e484520a4dc4dd6672a7f17",
      "e6dd759dedd84fe3afde7fafadbdc5e6",
      "074323727f34416c895035b6d28e3738",
      "43204103508c4482921d3f6bd45fe366",
      "4271f826e55c4fee959a8097d9695e36",
      "97e08226970849feaea2b8c4a2c59162",
      "23c9ac6aff0448a2a69bf53e98c1b64a",
      "1d7e20161e9248e6a41c541517122a17",
      "a272d658182140b29fe755334af326c0",
      "758e0c34b07e4c168617e8857e09b8fa"
     ]
    },
    "id": "tvizBRhSpzyU",
    "outputId": "0246a34e-d5ce-4134-abf5-74e7a890bbf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.65 s (started: 2022-10-14 12:53:56 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# cargar modelo detector de objetos\n",
    "device = 'cuda'\n",
    "#device = 'cpu'\n",
    "model_path = '/home/jupyter/Score/Modelos/model_cf_12y3_1.pth'\n",
    "num_classes = 2\n",
    "od_model = get_object_detection_model(num_classes)\n",
    "od_model_dict = torch.load(model_path, map_location=torch.device(device))\n",
    "od_model.load_state_dict(od_model_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vcMJ6vYakwP"
   },
   "source": [
    "# Función de score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JS5mOP-lff98",
    "outputId": "7be3675c-e1b8-4944-8864-97d723323d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 818 µs (started: 2022-10-14 12:54:03 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import urllib\n",
    "import math\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAPuxMfOZuSW",
    "outputId": "725adb2b-f909-4ff3-f731-a4fdf0f62188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.1 ms (started: 2022-10-14 12:54:03 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "# supuesto: tabla con enlaces a cada fotografía\n",
    "\n",
    "def score(url, classificator_1, classificator_2, detector, pesos = {'w_prod': 0.4, 'w_notface': 0.1,\n",
    "                                                 'w_label': 0.3, 'w_num': 0.1, 'w_contx': 0.2},\n",
    "          thresholds = {'t_prod': 0.5, 't_face': 0.5, 't_label': 0.5, 't_num': 0.5, 't_ctx_down': 0.2, \n",
    "                        't_ctx_up': 0.65}, device = 'cuda'):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "      url (str): url donde se encuentra la imagen\n",
    "      classificator_1 (modelo): clasificador multi-etiqueta para detectar la etiqueta del paquete\n",
    "      classificator_2 (modelo): clasificador multi-etiqueta para detectar la cara y el domicilio\n",
    "      detector (modelo): detector de objetos para identificar el paquete y su bbox respectivo\n",
    "      pesos (dict): diccionario con valores para cada peso, es decir,\n",
    "      w_prod (product), w_notface (without face), w_label (product label), \n",
    "      w_num (address number) y w_contx (context)\n",
    "      thresholds = diccionario con valores de umbral para cada criterio, es decir,\n",
    "      t_prod (product), t_face (face detector), t_label (product label) y \n",
    "      t_num (address number)\n",
    "      \n",
    "  Obs: los pesos deben sumar 1 para todos los criterios menos el del numero de domicilio. Este\n",
    "       ultimo corresponde a un beneficio de +0.1 si es que aparece en la fotografía.\n",
    "\n",
    "  Returns:\n",
    "      result_data (dataFrame): cada una de las columnas del dataFrame corresponde a la predicción\n",
    "      de cada criterio sobre cierto umbral, los scores (confianza del modelo) de cada criterio y \n",
    "      la nota de la foto (score).\n",
    "      t_img_0 (tensor): imagen procesada\n",
    "      b (array): bounding boxes de la imagen  \n",
    "  \"\"\"\n",
    "  # evaluar con gpu o cpu \n",
    "  device = torch.device(device)\n",
    "\n",
    "  classificator_1.to(device)\n",
    "  classificator_1.eval()  \n",
    "  classificator_2.to(device)\n",
    "  classificator_2.eval()           \n",
    "  detector.to(device)\n",
    "  detector.eval()\n",
    "  # transformación para clasificador\n",
    "  transformations = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.Resize((224, 224)),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                                      std=[0.229, 0.224, 0.225]),\n",
    "                                                 ])\n",
    "  with torch.no_grad():\n",
    "    # Obtener imagen\n",
    "    try:\n",
    "        url_open = urllib.request.urlopen(url)\n",
    "        image_cv = np.asarray(bytearray(url_open.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image_cv, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #-----------------------------------------------------------------------------\n",
    "        # CLASIFICADOR MULTI-ETIQUETA\n",
    "        # transformación para aplicar clasificador\n",
    "        t_img = transformations(image)\n",
    "        img = t_img.unsqueeze(dim = 0)\n",
    "        # obtener clasificación\n",
    "        #---------------------------clasificador 1--------------------------------\n",
    "        label_base = classificator_1(img.to(device))\n",
    "        #---------------------------clasificador 2--------------------------------\n",
    "        label_etiqueta = classificator_2(img.to(device))\n",
    "        # obtener score\n",
    "        score = torch.sigmoid(label_base['label']).squeeze()\n",
    "        score_etiqueta = torch.sigmoid(label_etiqueta['label']).squeeze()\n",
    "        # analizar score para 'etiqueta'\n",
    "        s_etiqueta = score_etiqueta[0].item()\n",
    "        if s_etiqueta >= thresholds['t_label']:\n",
    "          etiqueta = 1\n",
    "        else:\n",
    "          etiqueta = 0\n",
    "        # analizar score para 'n° domicilio'\n",
    "        s_domicilio = score[1].item()\n",
    "        if s_domicilio >= thresholds['t_num']:\n",
    "          domicilio = 1\n",
    "        else:\n",
    "          domicilio = 0\n",
    "        # analizar score para 'cara'\n",
    "        s_cara = score[2].item()\n",
    "        s_no_cara = 1-s_cara\n",
    "        if s_cara >= thresholds['t_face']:\n",
    "          no_cara = 0\n",
    "        else:\n",
    "          no_cara = 1\n",
    "        #-----------------------------------------------------------------------------\n",
    "        # DETECTOR DE OBJETOS\n",
    "        # transformación para aplicar detector\n",
    "        t_img_0 = transform.resize(image, (480, 480))\n",
    "        # obtener area de la imagen\n",
    "        area_img = t_img_0.shape[0]*t_img_0.shape[1]\n",
    "        t_img = torch.Tensor(t_img_0).permute(2,0,1).to(device)\n",
    "        od_prediction = od_model([t_img])\n",
    "        \n",
    "        # analizar score para 'paquete'\n",
    "        s_paquete = max(od_prediction[0]['scores']).item()\n",
    "        if od_prediction[0]['labels'].shape[0] > 0 and \\\n",
    "        s_paquete >= thresholds['t_prod']:\n",
    "          paquete = 1\n",
    "        else:\n",
    "          paquete = 0 \n",
    "        # determinar unión de todos los bbox que encierren a un paquete (score >= t_prod) \n",
    "        boxes = od_prediction[0]['boxes'].to(device)\n",
    "        scores = od_prediction[0]['scores'].to(device)\n",
    "        scores = torch.where(scores >= thresholds['t_prod'], 1, 0)\n",
    "        scores = torch.unsqueeze(scores, dim=0)\n",
    "        scores_t = torch.transpose(scores, 0, 1)\n",
    "        mult = torch.mul(boxes, scores_t)\n",
    "        b = mult[mult.sum(dim=1) != 0] # eliminar filas con puros ceros\n",
    "        l =list(range(b.size()[0]))\n",
    "        # recorrer cajas y calcular inter-area para cada combinación\n",
    "        indice = 0\n",
    "        interArea = 0\n",
    "        for i in itertools.combinations(l, r=2):\n",
    "          # obtener coordenadas de la inter-area\n",
    "          x0 = max(b[i[0]][0], b[i[1]][0])\n",
    "          y0 = max(b[i[0]][1], b[i[1]][1])\n",
    "          x1 = min(b[i[0]][2], b[i[1]][2])\n",
    "          y1 = min(b[i[0]][3], b[i[1]][3])\n",
    "    \n",
    "          # calcular inter-area\n",
    "          dif_x = x0-x1\n",
    "          dif_y = y0-y1\n",
    "          # se verifica que las esquinas de la interArea esten bien ubicadas \n",
    "          if dif_x < 0 and dif_y < 0:\n",
    "            interArea += dif_x*dif_y\n",
    "          ##interArea += abs(x0-x1)*abs(y0-y1)\n",
    "      \n",
    "        # sumar areas de cada bbox\n",
    "        area_total_bbox = 0\n",
    "        for box in b:\n",
    "          # calcular area de cada bbox\n",
    "          area_bbox = abs(box[0]-box[2])*abs(box[1]-box[3])\n",
    "          # calcular area total de bbox\n",
    "          area_total_bbox += area_bbox\n",
    "    \n",
    "        # calcular la union de las areas de cada bbox\n",
    "        union = area_total_bbox - interArea\n",
    "    \n",
    "        # calcular contexto\n",
    "        if torch.is_tensor(union):\n",
    "          contexto = union.item()/area_img\n",
    "      \n",
    "        else:\n",
    "          contexto = union/area_img\n",
    "        \n",
    "        # analizar contexto \n",
    "        if (contexto >= thresholds['t_ctx_down']) and (contexto <= thresholds['t_ctx_up']):\n",
    "          ctx_value = 1\n",
    "    \n",
    "        else:\n",
    "          ctx_value = 0\n",
    "      \n",
    "        # calcular score\n",
    "        score = pesos['w_prod']*paquete + pesos['w_label']*etiqueta + \\\n",
    "        pesos['w_notface']*no_cara + pesos['w_num']*domicilio + pesos['w_contx']*ctx_value\n",
    "        \n",
    "        enlace = 'correcto'\n",
    "    \n",
    "    except:\n",
    "        paquete = None\n",
    "        s_paquete = None\n",
    "        etiqueta = None\n",
    "        s_etiqueta = None\n",
    "        no_cara = None\n",
    "        s_no_cara = None\n",
    "        domicilio = None\n",
    "        s_domicilio = None\n",
    "        contexto = None\n",
    "        ctx_value = None\n",
    "        score = None\n",
    "        t_img_0 = None\n",
    "        b = None\n",
    "        enlace = 'incorrecto'\n",
    "        \n",
    "    # Vector de salida (fila) Prob. Etiqueta producto, Etiqueta producto, Prob. Numero domicilio, Numero domicilio\n",
    "    ##result = np.array([paquete, etiqueta, no_cara, domicilio, contexto, ctx_value, score])\n",
    "    result = np.array([paquete, s_paquete, etiqueta, s_etiqueta, no_cara, s_no_cara, domicilio,\\\n",
    "                       s_domicilio, contexto, ctx_value, score, enlace])\n",
    "    # Se hace un dataframe\n",
    "    ##result_data = pd.DataFrame([result], [0], columns=['paquete', 'etiqueta_producto', 'sin_rostro',\\\n",
    "    ##                                              'numero_domicilio', 'contexto', 'ctx_value', 'score'])\n",
    "    result_data = pd.DataFrame([result], [0], columns=['paquete', 's_paquete', 'etiqueta_producto', \\\n",
    "                                                       's_etiqueta_producto', 'sin_rostro', 's_sin_rostro',\\\n",
    "                                                       'numero_domicilio', 's_numero_domicilio', 'contexto',\\\n",
    "                                                       'ctx_value', 'score', 'enlace'])\n",
    "    \n",
    "    return result_data, t_img_0, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.87 ms (started: 2022-10-14 12:54:03 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def prediccion_por_sample(sample, j, dataset = 'image_recognition', full_table = 'prediction_table', \n",
    "               random_table = 'random_table', random_table_backup  = 'random_table_backup',\n",
    "              n=100, n_r=1):\n",
    "    import time\n",
    "    t_ini = time.time()\n",
    "    # Generar tabla \n",
    "    df_base = pd.DataFrame(columns = ['SOC', 'url', 'plate_num', 'provider_id', 'provider_verify_digit',\n",
    "                                      'provider_name', 'driver_id',\t'driver_verify_digit',\t\n",
    "                                      'driver_name', 'driver_last_name', 'event_crte_tmst',\n",
    "                                      'dfl_crte_tmst','paquete', 's_paquete', 'etiqueta_producto',\n",
    "                                      's_etiqueta_producto', 'sin_rostro', 's_sin_rostro',\n",
    "                                      'numero_domicilio', 's_numero_domicilio', 'contexto',\n",
    "                                      'ctx_value', 'score', 'enlace'])\n",
    "    \n",
    "    thres = {'t_prod': 0.5, 't_face': 0.6491, 't_label': 0.3, 't_num': 0.6, 't_ctx_down': 0.2, \n",
    "                            't_ctx_up': 0.65}\n",
    "    \n",
    "    largo_dataset = len(sample)\n",
    "    print('tamaño sample:',largo_dataset)\n",
    "    for i in range(len(sample)):\n",
    "      i+=j\n",
    "      url = sample.loc[[i]]['url'].item()\n",
    "      df1 = sample.loc[[i]].reset_index()\n",
    "      #aplicar modelo que retornara df2\n",
    "      df2, _, _ = score(url, ml_model_1, ml_model_2, od_model, thresholds = thres)\n",
    "      #df2, _, _ = score(url, ml_model_1, ml_model_2, od_model, thresholds = thres, device = 'cpu')\n",
    "      df3 = pd.concat((df1,df2), axis =1)\n",
    "      df_base = pd.concat((df_base,df3), ignore_index= True)\n",
    "      # revisión cada 100 imágenes \n",
    "      if i>0 and i%n==0:\n",
    "        print(i,'fotografías procesadas del total del dataset')      \n",
    "    t_fin = time.time()\n",
    "    delta_time = t_fin-t_ini \n",
    "    # Hacer copia del modelo\n",
    "    df_base_copy1 = df_base.copy()\n",
    "\n",
    "    # Cambiar tipo de dato de \"score\" a float\n",
    "    df_base_copy1[\"score\"] = pd.to_numeric(df_base_copy1[\"score\"])\n",
    "    # Seleccionar SOC que tiene mayor \"score\"\n",
    "    idx_max_score = df_base_copy1.groupby(['SOC'])['score'].transform(max) == df_base_copy1['score']\n",
    "    ##df_base_copy2 = df_base_copy1[idx_max_score].drop_duplicates(['SOC'])\n",
    "    # Agrupar por SOC y dejar indice\n",
    "    ##df_base_copy2 = df_base_copy1[['SOC', 'index', 'score']].groupby(['SOC'], sort = False).score.max()\n",
    "\n",
    "    # Agrupar por RUT, normalizar los nombres y dejar indice\n",
    "    #.agg(lambda x:x.value_counts().index[0])\n",
    "    df_base_copy3 = df_base_copy1[['provider_name', 'provider_id']].groupby(['provider_id'], sort = False)['provider_name'].transform('first').to_frame()\n",
    "    df_base_copy3['index'] = df_base_copy1['index']\n",
    "\n",
    "    # \"merge\" del dataset normalizado y el dataset original, con respecto al indice\n",
    "    df_base_copy4 = pd.merge(df_base_copy3, df_base_copy1, how='left', on='index')\n",
    "\n",
    "    # \"merge\" del dataset agrupado por SOC y el dataset anterior, con respecto al indice\n",
    "\n",
    "    ##df_base_final  = pd.concat([df_base_copy2, df_base_copy4], axis=1, join=\"inner\")\n",
    "    df_base_final = df_base_copy1[idx_max_score].drop_duplicates(['SOC'])\n",
    "\n",
    "    ##df_base_final = pd.merge(df_base_copy2, df_base_copy4, how='left', on='index')\n",
    "\n",
    "    # arreglar fechas\n",
    "    df_base_final['dfl_crte_tmst'] = df_base_final['dfl_crte_tmst'].dt.tz_localize(None)\n",
    "    df_base_final['event_crte_tmst'] = df_base_final['event_crte_tmst'].dt.tz_localize(None)\n",
    "    # guardar largo del dataset\n",
    "    new_df_base_final = df_base_final.assign(len_data = largo_dataset)\n",
    "    # guardar tiempo de ejecución\n",
    "    new_df_base_final = new_df_base_final.assign(execution_time_model = delta_time)\n",
    "    # generar tabla aleatoria\n",
    "    df_copy = new_df_base_final.copy()\n",
    "    df_filtrado = df_copy[(df_copy.enlace != 'incorrecto')]\n",
    "    df_filtrado=df_filtrado.assign(paquete_em=\"\", etiqueta_em=\"\", domicilio_em=\"\", rostro_em=\"\")\n",
    "    import pandas_gbq\n",
    "    # ubicación de destino para tabla procesada\n",
    "    destination_full_table = dataset + '.' + full_table\n",
    "    # anexar tabla de predicciones\n",
    "    pandas_gbq.to_gbq(new_df_base_final, destination_full_table, project_id='tc-sc-bi-bigdata-corp-tsod-dev', if_exists = 'append')\n",
    "    print(\"Se almacenó exitosamente tabla de predicciones\")\n",
    "    try:\n",
    "        # seleccionar pequeño conjunto de datos aleatorios de cada sample\n",
    "        # intentar generar tabla aleatoria\n",
    "        random_sample = df_filtrado.sample(n_r, frac=None, replace=False, weights=None, random_state=None)\n",
    "        # destino de tabla aleatoria\n",
    "        destination_random_table = dataset + '.' + random_table\n",
    "        # anexar tabla aleatoria a tabla generada durante el dia\n",
    "        pandas_gbq.to_gbq(random_sample, destination_random_table, project_id='tc-sc-bi-bigdata-corp-tsod-dev', if_exists = 'append')\n",
    "        print(\"Se almacenó exitosamente sub-tabla aleatoria\")\n",
    "        # anexar tabla aleatoria, con todas las tablas aleatorias generadas en dias anteriores\n",
    "        # para tenerlas de respaldo\n",
    "        destination_random_table_backup = dataset + '.' + random_table_backup\n",
    "        pandas_gbq.to_gbq(random_sample, destination_random_table_backup, project_id='tc-sc-bi-bigdata-corp-tsod-dev', if_exists = 'append')  \n",
    "        print(\"Se almacenó exitosamente sub-tabla aleatoria al backup\")\n",
    "    except:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.72 ms (started: 2022-10-14 12:54:03 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def predicciones_dataset(logger, fhandler,dataFrame=df_images, n_s=1000, n_i=100, n_r=200, dataset = 'image_recognition', \n",
    "                             full_table = 'prediction_table', random_table = 'random_table',\n",
    "                             random_table_backup  = 'random_table_backup', sample_partida = None):\n",
    "    # sample partida corresponde a el último sample que se pudo guardar \n",
    "    import math\n",
    "    # inicializar \n",
    "    count = 0\n",
    "    tamaño = len(dataFrame)\n",
    "    if tamaño/n_s <= n_r:\n",
    "        n_r2 = math.ceil(n_r/(tamaño/n_s))\n",
    "    else: \n",
    "        n_r2 = 1\n",
    "    if sample_partida:\n",
    "        ini = sample_partida*n_s\n",
    "        fin = ini\n",
    "        total_samples = math.ceil(tamaño/n_s)-sample_partida\n",
    "        partida = n_s*sample_partida+1\n",
    "    else:\n",
    "        ini = 0 \n",
    "        total_samples = math.ceil(tamaño/n_s)\n",
    "        partida = 0\n",
    "    # generar samples cada n elementos\n",
    "    termino=0\n",
    "    for n_filas in range(tamaño+1):\n",
    "        n_filas += partida\n",
    "        if n_filas > 0  and n_filas%n_s == 0:\n",
    "            fin = n_filas\n",
    "            sample = dataFrame.iloc[ini:fin]\n",
    "            prediccion_por_sample(sample,ini, dataset, full_table, \n",
    "               random_table, random_table_backup, n_i, n_r2)\n",
    "            ini+=n_s\n",
    "            count+=1\n",
    "            print(count, 'samples procesados de', total_samples)\n",
    "            ################################# logger\n",
    "            message = str(count) + ' sample(s) procesados de ' +  str(total_samples)\n",
    "            logging.info(message)\n",
    "        # generar ultimo sample en caso de que no se pueda dividir en partes enteras\n",
    "        if n_filas == tamaño and n_filas%n_s != 0:\n",
    "            sample = dataFrame.iloc[fin:n_filas]\n",
    "            prediccion_por_sample(sample,fin, dataset, full_table, random_table, \n",
    "                       random_table_backup, n_i, n_r2)\n",
    "            count+=1\n",
    "            termino = 1\n",
    "            print(count, 'samples procesados de', total_sample)\n",
    "            ################################# logger\n",
    "            message = str(count) + ' sample(s) procesados de ' +  str(total_samples)\n",
    "            logging.info(message)\n",
    "        if termino == 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño sample: 12591\n",
      "500 fotografías procesadas del total del dataset\n",
      "1000 fotografías procesadas del total del dataset\n",
      "1500 fotografías procesadas del total del dataset\n",
      "2000 fotografías procesadas del total del dataset\n",
      "2500 fotografías procesadas del total del dataset\n",
      "3000 fotografías procesadas del total del dataset\n",
      "3500 fotografías procesadas del total del dataset\n",
      "4000 fotografías procesadas del total del dataset\n",
      "5500 fotografías procesadas del total del dataset\n",
      "6000 fotografías procesadas del total del dataset\n",
      "6500 fotografías procesadas del total del dataset\n",
      "7000 fotografías procesadas del total del dataset\n",
      "7500 fotografías procesadas del total del dataset\n",
      "8000 fotografías procesadas del total del dataset\n",
      "8500 fotografías procesadas del total del dataset\n",
      "9000 fotografías procesadas del total del dataset\n",
      "9500 fotografías procesadas del total del dataset\n",
      "10000 fotografías procesadas del total del dataset\n",
      "10500 fotografías procesadas del total del dataset\n",
      "11000 fotografías procesadas del total del dataset\n",
      "11500 fotografías procesadas del total del dataset\n",
      "12000 fotografías procesadas del total del dataset\n",
      "12500 fotografías procesadas del total del dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12865.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se almacenó exitosamente tabla de predicciones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15947.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se almacenó exitosamente sub-tabla aleatoria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18808.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se almacenó exitosamente sub-tabla aleatoria al backup\n",
      "1 samples procesados de 1\n",
      "time: 2h 48min 7s (started: 2022-10-14 12:54:03 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import date\n",
    "##################################\n",
    "today = date.today()\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='/home/jupyter/Score/logs/k1_test_log_30_09_22.log', mode='a')\n",
    "fhandler.setLevel(logging.INFO)\n",
    "logger.addHandler(fhandler)\n",
    "logging.info('Fecha: ' + str(today))\n",
    "logging.info('Kernel: ' + str(1))\n",
    "\n",
    "predicciones_dataset(logger, fhandler, dataFrame=df_images1, n_s=len(df_images1), n_i=500, n_r=200, dataset = 'image_recognition', \n",
    "                             full_table = 'prediction_table_prueba_2', random_table = 'random_table_prueba_10',\n",
    "                             random_table_backup  = 'random_table_backup_prueba_2', sample_partida = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05887b1a958f4535938c3a9208b4ebaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9597f48902e54c7a9989484bcf6a239d",
      "placeholder": "​",
      "style": "IPY_MODEL_4a4aad02b8d24bffa799e6a5fdd4e006",
      "value": " 340M/340M [00:01&lt;00:00, 147MB/s]"
     }
    },
    "074323727f34416c895035b6d28e3738": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a272d658182140b29fe755334af326c0",
      "placeholder": "​",
      "style": "IPY_MODEL_758e0c34b07e4c168617e8857e09b8fa",
      "value": " 160M/160M [00:01&lt;00:00, 90.2MB/s]"
     }
    },
    "1d7e20161e9248e6a41c541517122a17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "23c9ac6aff0448a2a69bf53e98c1b64a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32a0c7587cf74eeb98287fdf4767f938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e932cf1b4e484520a4dc4dd6672a7f17",
       "IPY_MODEL_e6dd759dedd84fe3afde7fafadbdc5e6",
       "IPY_MODEL_074323727f34416c895035b6d28e3738"
      ],
      "layout": "IPY_MODEL_43204103508c4482921d3f6bd45fe366"
     }
    },
    "3a331d5960ec443eb8064094c6f9a414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b131ad046e94d0fa9405998f77117c1",
      "placeholder": "​",
      "style": "IPY_MODEL_719e9bde165b4db9816907ef904a8f67",
      "value": "100%"
     }
    },
    "3c468e9910384933988fb43f15ec7987": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4271f826e55c4fee959a8097d9695e36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43204103508c4482921d3f6bd45fe366": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46b4809efd1946ac911ccc2999bce65d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a4aad02b8d24bffa799e6a5fdd4e006": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4bb2db3d2e644c26800558b8cdbc87fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a331d5960ec443eb8064094c6f9a414",
       "IPY_MODEL_a9e479cebc604561a5285a26a9b3cf9c",
       "IPY_MODEL_f94af2ae961249f1a2c6888009162afe"
      ],
      "layout": "IPY_MODEL_505388778fc745549e1be6b4478ada1b"
     }
    },
    "505388778fc745549e1be6b4478ada1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "719e9bde165b4db9816907ef904a8f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "758e0c34b07e4c168617e8857e09b8fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78b8a851199c421694811a3d2b09d77a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b131ad046e94d0fa9405998f77117c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9597f48902e54c7a9989484bcf6a239d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97e08226970849feaea2b8c4a2c59162": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fb6091980f34f1fa8b8a6168760a397": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0c5367310094e45baa5e4f21daa819a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a23ac5b3ea2d4bd9950f901288642e51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a272d658182140b29fe755334af326c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4d602abedbf472ba8443b587b7172a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e369973d094144a583efe831a749932e",
       "IPY_MODEL_f185edec20214d4f9174944db636ce7b",
       "IPY_MODEL_05887b1a958f4535938c3a9208b4ebaf"
      ],
      "layout": "IPY_MODEL_a23ac5b3ea2d4bd9950f901288642e51"
     }
    },
    "a9e479cebc604561a5285a26a9b3cf9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fb6091980f34f1fa8b8a6168760a397",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46b4809efd1946ac911ccc2999bce65d",
      "value": 167502836
     }
    },
    "c084ae1be8e94b6da09dde8e90362301": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d482f72576e946f59c20fea52f2973c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e369973d094144a583efe831a749932e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d482f72576e946f59c20fea52f2973c3",
      "placeholder": "​",
      "style": "IPY_MODEL_a0c5367310094e45baa5e4f21daa819a",
      "value": "100%"
     }
    },
    "e6dd759dedd84fe3afde7fafadbdc5e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23c9ac6aff0448a2a69bf53e98c1b64a",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d7e20161e9248e6a41c541517122a17",
      "value": 167502836
     }
    },
    "e932cf1b4e484520a4dc4dd6672a7f17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4271f826e55c4fee959a8097d9695e36",
      "placeholder": "​",
      "style": "IPY_MODEL_97e08226970849feaea2b8c4a2c59162",
      "value": "100%"
     }
    },
    "f185edec20214d4f9174944db636ce7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3c586b991004e839c47ee46163195e8",
      "max": 356082095,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_78b8a851199c421694811a3d2b09d77a",
      "value": 356082095
     }
    },
    "f3c586b991004e839c47ee46163195e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f94af2ae961249f1a2c6888009162afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c084ae1be8e94b6da09dde8e90362301",
      "placeholder": "​",
      "style": "IPY_MODEL_3c468e9910384933988fb43f15ec7987",
      "value": " 160M/160M [00:01&lt;00:00, 121MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
